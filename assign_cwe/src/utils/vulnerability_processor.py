# src/utils/vulnerability_processor.py

"""
Classes for processing vulnerability information.
"""

import os
import json
import csv
import time
import re
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from models.vulnerability_info import VulnerabilityInfo, ProcessingResult
from utils.vulnerability_retriever import VulnerabilityInfoRetriever
from utils.logger import get_logger, setup_logging
from loguru import logger as loguru_logger

import logging
from utils.file_ops import (
    ensure_directory,
    save_markdown,
    save_json,
    save_csv,
    append_csv_row,
    read_csv
)
from config.settings import ConfigManager
from agents.enhanced_llm_with_relationships import RelationshipEnhancedLLMAgent


logger = get_logger(__name__)

class VulnerabilityProcessor:
    """Handles the processing and saving of vulnerability analysis results."""
    
    def __init__(self, kb, output_dir: str, config: ConfigManager):
        """
        Initialize the processor.
        
        Args:
            kb: Knowledge base instance
            output_dir: Directory to store results
            config: Configuration manager
        """
        self.kb = kb
        self.output_dir = output_dir
        self.config = config
        self.info_retriever = VulnerabilityInfoRetriever(config, output_dir)
        
        # Ensure output directory exists
        ensure_directory(output_dir)
    
    
    def cleanup_cve_logger(self, cve_logger):
        """Clean up a CVE-specific logger."""
        if cve_logger:
            for handler in cve_logger.handlers[:]:
                handler.close()
                cve_logger.removeHandler(handler)
            
            # Remove filters
            for filter in cve_logger.filters[:]:
                cve_logger.removeFilter(filter)    
    
    
    def setup_cve_logger(self, cve_id):
        """
        Set up a dedicated logger for a single CVE that writes to a fresh CVE-specific file
        and allows messages to propagate to the root logger.
        
        Args:
            cve_id: The CVE identifier
            
        Returns:
            A logger configured to write to a CVE-specific log file
        """
        cve_dir = os.path.join(self.output_dir, cve_id)
        ensure_directory(cve_dir)
        log_file = os.path.join(cve_dir, f"{cve_id}_processing.log")
        
        # Create a new logger with the CVE ID as its name
        cve_logger_name = f"cve_logger_{cve_id}"
        cve_logger = logging.getLogger(cve_logger_name)
        
        # Reset this logger (remove any existing handlers)
        for handler in cve_logger.handlers[:]:
            handler.close()
            cve_logger.removeHandler(handler)
        
        # Set up the file handler with mode='w' to create a new file
        file_handler = logging.FileHandler(log_file, mode='w')
        file_formatter = logging.Formatter('%(asctime)s | %(levelname)-8s | %(message)s', '%Y-%m-%d %H:%M:%S')
        file_handler.setFormatter(file_formatter)
        
        # Set the level and add the handler
        cve_logger.setLevel(logging.DEBUG)
        cve_logger.addHandler(file_handler)
        
        # Important: Set propagate to True so logs also reach the root logger for the main program log
        cve_logger.propagate = True
        
        return cve_logger
        
    
    # Define a local function to process the resolution
    def remove_nested_markdown_blocks(self, text):
        """Remove nested markdown code blocks within markdown."""
        import re
        markdown_block_pattern = r'```markdown\s*(.*?)\s*```'
        return re.sub(markdown_block_pattern, lambda match: match.group(1), text, flags=re.DOTALL)


    def prepare_vulnerability_info(self, cve_id: str, description: str, cve_logger) -> Tuple[VulnerabilityInfo, str]:
        """
        Gather comprehensive vulnerability information and prepare enhanced query.
        """
        cve_logger.info("Gathering vulnerability information")
        
        # Create the CVE directory path
        cve_dir = os.path.join(self.output_dir, cve_id)
        ensure_directory(cve_dir)  # Make sure the directory exists
        
        # Get vulnerability information
        vuln_info = self.info_retriever.get_vulnerability_info(cve_id)
        vuln_info.description = description  # Update with provided description
        
        # Extract keyphrases for highlighting
        rootcause = None
        weakness = None
        if vuln_info.key_phrases:
            rootcause = vuln_info.key_phrases.get('rootcause')
            weakness = vuln_info.key_phrases.get('weakness')

        # Gather retriever results with keyphrases
        relevant_cwes = []
        try:
            keyphrases = {}
            if vuln_info.key_phrases:
                if vuln_info.key_phrases.get('rootcause'):
                    keyphrases['rootcause'] = vuln_info.key_phrases['rootcause']
                if vuln_info.key_phrases.get('weakness'):
                    keyphrases['weakness'] = vuln_info.key_phrases['weakness']
            
            # Call search once with all retrievers enabled
            search_results = self.kb.retriever.search(
                description, 
                keyphrases=keyphrases,
                k=10,
                use_graph=True,
                use_rag=True,
                use_sparse=True,
                rerank=False,
                cve_id=cve_id
            )
            
            # Extract consolidated results
            all_results = search_results.get("all_results", [])
            result_sources = search_results.get("result_sources", {})
            result_scores = search_results.get("result_scores", {})
            retriever_results = search_results.get("retriever_results", {})
            
            # Log stats about retriever results
            dense_results = retriever_results.get("dense", [])
            graph_results = retriever_results.get("graph", [])
            sparse_results = retriever_results.get("sparse", [])
            
            cve_logger.info(f"Dense search returned {len(dense_results)} results")
            cve_logger.info(f"Graph search returned {len(graph_results)} results")
            cve_logger.info(f"Sparse search returned {len(sparse_results)} results")
            
                        
            # Log raw sparse results details (including raw similarity scores)
            for idx, res in enumerate(sparse_results):
                if "score" in res:  # Sparse retriever format
                    raw_score = res.get("score", 0.0)
                    doc_id = res.get("cwe_id", "unknown")
                    cve_logger.debug(f"Sparse result {idx+1} (cwe_id: {doc_id}) raw score: {raw_score}")
                else:  # Dense or graph retriever format
                    raw_score = res.get("similarity", 0.0)
                    doc_id = res.get("metadata", {}).get("doc_id", "unknown")
                    cve_logger.debug(f"Result {idx+1} (doc_id: {doc_id}) similarity: {raw_score}")            
                        
            if all_results:
                consolidated_results = self.kb.retriever.consolidate_results(
                    all_results, result_sources, result_scores
                )

                # Log each consolidated result's similarity score
                for idx, res in enumerate(consolidated_results):
                    score = res.get("similarity", 0.0)
                    doc_id = res.get("metadata", {}).get("doc_id", "unknown")
                    cve_logger.debug(f"Consolidated result {idx+1} (doc_id: {doc_id}) similarity: {score}")
                                
                # Sort by combined score
                sorted_results = sorted(
                    consolidated_results,
                    key=lambda x: x.get('similarity', 0),
                    reverse=True
                )
                
                # Save consolidated results using the public method
                self.kb.retriever.save_consolidated_results(
                    cve_id, description, keyphrases, sorted_results, 10
                )
                
                # Use the consolidated results
                relevant_cwes = sorted_results
                cve_logger.info(f"Used retriever's consolidation methods for {len(relevant_cwes)} CWEs")
            else:
                # No results found - use empty list
                relevant_cwes = []
                cve_logger.info("No CWEs found by any retriever")
            

            # Log final relevant CWEs with their normalized similarity scores
            for idx, cwe in enumerate(relevant_cwes):
                score = cwe.get("similarity", 0.0)
                doc_id = cwe.get("metadata", {}).get("doc_id", "unknown")
                cve_logger.debug(f"Final CWE {idx+1} (doc_id: {doc_id}) similarity: {score}")
            
            
            # Store in vulnerability info
            vuln_info.relevant_cwes = relevant_cwes
            cve_logger.info(f"Retrieved {len(relevant_cwes)} relevant CWEs with multi-retriever approach")
            
            # Save retriever results
            save_json(
                os.path.join(cve_dir, f"{cve_id}_retriever_results.json"),
                {
                    "keyphrases_used": keyphrases,
                    "dense_results_count": len(dense_results),
                    "graph_results_count": len(graph_results),
                    "sparse_results_count": len(sparse_results),
                    "total_unique_results": len(relevant_cwes),
                    "relevant_cwes": [
                        {
                            "doc_id": cwe["metadata"]["doc_id"],
                            "name": cwe["metadata"].get("name", ""),
                            "source": cwe["metadata"].get("source", "unknown"),
                            "similarity": cwe.get("similarity", 0.0),
                            "relationships_count": len(cwe["metadata"].get("relationships", []))
                        } for cwe in relevant_cwes
                    ]
                }
            )
            
            # Fix for the error in EnhancedLLMAgent._build_enhanced_context
            # Save a modified version of the results for use by the EnhancedLLMAgent
            # This avoids the "string indices must be integers, not 'str'" error
            agent_results = []
            for result in relevant_cwes:
                # Each result should be a simple dict with 'metadata' key
                agent_results.append(result)
                
            # Save special results file for agents
            agent_results_file = os.path.join(cve_dir, f"{cve_id}_agent_cwe_results.json")
            save_json(agent_results_file, agent_results)
            
            
            # Save similarity summary as a separate file if it exists
            if hasattr(vuln_info, 'similarity_summary') and vuln_info.similarity_summary:
                similarity_data = {
                    "cve_id": cve_id,
                    "consensus_cwe": vuln_info.similarity_summary.consensus_cwe,
                    "top_cwes": vuln_info.similarity_summary.top_cwes,
                    "confidence_levels": vuln_info.similarity_summary.confidence_levels,
                    "total_samples": vuln_info.similarity_summary.total_samples
                }
                
                # Save to a separate file
                similarity_file = os.path.join(cve_dir, f"{cve_id}_similar_cves.json")
                save_json(similarity_file, similarity_data)
                cve_logger.info(f"Saved similarity summary to {similarity_file}")
                
        except Exception as e:
            cve_logger.warning(f"Retriever search failed: {e}")
            
        # Build enhanced query with highlighted keyphrases and retriever results
        enhanced_query = self._build_enhanced_query(
            cve_id, 
            description, 
            vuln_info.key_phrases, 
            vuln_info.similarity_summary,
            vuln_info.reference_content,
            relevant_cwes,
            rootcause,
            weakness
        )
        
        return vuln_info, enhanced_query
    
    
    def _build_enhanced_query(self, cve_id, description, key_phrases, similarity_summary, 
                            reference_content, relevant_cwes=None, rootcause=None, weakness=None) -> str:
        """
        Build an enhanced query with comprehensive vulnerability information including detailed retriever results.
        
        Args:
            cve_id: The CVE identifier
            description: Vulnerability description
            key_phrases: Dictionary of key phrases
            similarity_summary: Summary of similar CVEs
            reference_content: Reference content text
            relevant_cwes: List of relevant CWEs from retriever
            rootcause: Rootcause keyphrase (string or list)
            weakness: Weakness keyphrase (string or list)
            
        Returns:
            Enhanced query string with markdown formatting
        """
        # Helper function to safely check if a keyphrase (string or list) is in the description
        def is_in_description(keyphrase, text):
            if isinstance(keyphrase, str):
                return keyphrase and keyphrase in text
            elif isinstance(keyphrase, list):
                return any(phrase and isinstance(phrase, str) and phrase in text 
                        for phrase in keyphrase)
            return False
        
        # Helper function to highlight keyphrases in text
        def highlight_keyphrases(text, keyphrase):
            if isinstance(keyphrase, str) and keyphrase:
                return text.replace(keyphrase, f"**{keyphrase}**")
            elif isinstance(keyphrase, list):
                highlighted = text
                for phrase in keyphrase:
                    if isinstance(phrase, str) and phrase:
                        highlighted = highlighted.replace(phrase, f"**{phrase}**")
                return highlighted
            return text
        
        # Helper function to format keyphrase value (string or list) for display
        def format_keyphrase_value(keyphrase):
            if isinstance(keyphrase, str):
                return keyphrase
            elif isinstance(keyphrase, list):
                # Filter out any non-string values and join remaining with " and "
                valid_phrases = [phrase for phrase in keyphrase 
                                if isinstance(phrase, str) and phrase]
                if valid_phrases:
                    return " and ".join(valid_phrases)
            return ""

        # Highlight keyphrases in the description if available
        highlighted_description = description
        
        # Highlight rootcause if it exists in the description
        if rootcause and is_in_description(rootcause, highlighted_description):
            highlighted_description = highlight_keyphrases(highlighted_description, rootcause)
        
        # Highlight weakness if it exists in the description
        if weakness and is_in_description(weakness, highlighted_description):
            highlighted_description = highlight_keyphrases(highlighted_description, weakness)

        # Add the highlighted description
        enhanced_query = f"## Vulnerability Description\n{highlighted_description}\n\n"

        # Add key phrases section if available
        if key_phrases:
            enhanced_query += "### Vulnerability Description Key Phrases\n"
            for key, value in key_phrases.items():
                if value:
                    # Make rootcause and weakness values bold
                    formatted_value = format_keyphrase_value(value)
                    if formatted_value:
                        if key in ['rootcause', 'weakness']:
                            enhanced_query += f"- **{key}:** **{formatted_value}**\n"
                        else:
                            enhanced_query += f"- **{key}:** {formatted_value}\n"
            enhanced_query += "\n"
        
        # Add similar CVE section if available
        if similarity_summary and similarity_summary.consensus_cwe:
            enhanced_query += "### CWE for similar CVE Descriptions\n"
            enhanced_query += f"### Primary CWE Match\n{similarity_summary.consensus_cwe}\n\n"
            
            if similarity_summary.top_cwes:
                enhanced_query += "#### Top CWEs\n"
                for cwe, count in similarity_summary.top_cwes[:3]:
                    enhanced_query += f"- {cwe} (Count: {count})\n"
                enhanced_query += "\n"
        
        # Add CVE Reference Link Content Summary if available
        if reference_content:
            enhanced_query += f"## CVE Reference Links Content Summary\n{reference_content}\n\n"

        # Add detailed retriever results if available
        if relevant_cwes:
            # Add a dedicated section for retriever results
            enhanced_query += "## Retriever Results\n\n"
            
            # Use the full table format if retriever has the necessary methods
            if hasattr(self.kb, 'retriever') and hasattr(self.kb.retriever, '_build_results_table') and hasattr(self.kb.retriever, '_format_full_results_table'):
                try:
                    # Build the comprehensive data structure
                    table_data = self.kb.retriever._build_results_table(relevant_cwes[:10])
                    
                    # Format using the full format with all columns
                    enhanced_query += "### Top Combined Results\n"
                    enhanced_query += self.kb.retriever._format_full_results_table(table_data)
                    enhanced_query += "\n"
                except Exception as e:
                    # Fall back to direct table construction if an error occurs
                    logger.warning(f"Error using retriever's table methods, falling back to direct construction: {e}")
                    self._build_direct_table(enhanced_query, relevant_cwes)
            else:
                # Fall back to direct table construction if methods aren't available
                self._build_direct_table(enhanced_query, relevant_cwes)
                
            # Track processed relationships to avoid duplicates
            processed_cwe_headers = set()
            processed_relationships = set()  # Track specific relationships

            # Only include relationships for top 5-7 CWEs
            for cwe in relevant_cwes[:7]:
                if 'metadata' in cwe and 'doc_id' in cwe['metadata'] and 'relationships' in cwe['metadata']:
                    doc_id = cwe['metadata']['doc_id']
                    relationships = cwe['metadata'].get('relationships', [])
                    
                    if relationships:
                        # Only add header if we have relationships and haven't processed this CWE yet
                        if doc_id not in processed_cwe_headers:
                            enhanced_query += f"\n#### {doc_id} Relationships\n"
                            processed_cwe_headers.add(doc_id)
                        
                        # Add relationship information, but track specific relationship combinations
                        for rel in relationships[:5]:  # Limit to 5 relationships per CWE
                            target_id = rel.get('target_id', '')
                            label = rel.get('label', '')
                            
                            if target_id and label:
                                # Create a unique key for this relationship
                                rel_key = f"{doc_id}|{label}|{target_id}"
                                
                                # Only add if we haven't seen this exact relationship before
                                if rel_key not in processed_relationships:
                                    enhanced_query += f"- {label} → {target_id}\n"
                                    processed_relationships.add(rel_key)
            
        return enhanced_query

    def _build_direct_table(self, enhanced_query, relevant_cwes):
        """
        Build a direct simple table when consolidated approach isn't available.
        This is a fallback method.
        
        Args:
            enhanced_query: The query string being built (modified in place)
            relevant_cwes: List of relevant CWEs
        """
        # Add Top Combined Results with Scores and Justification
        #enhanced_query += "### Top Combined Results\n"
        enhanced_query += "| Rank | CWE ID | Name | Type | Score | Found By |\n"
        enhanced_query += "|------|--------|------|------|-------|----------|\n"
        
        # Process top 10 CWEs
        for i, cwe in enumerate(relevant_cwes[:10]):
            metadata = cwe.get('metadata', {})
            doc_id = metadata.get('doc_id', 'Unknown')
            name = metadata.get('name', 'Unknown')
            cwe_type = metadata.get('type', 'Unknown')
            score = cwe.get('similarity', 0.0)
            
            # Get retriever sources
            score_info = metadata.get('score_info', {})
            retrievers = score_info.get('retrievers', [])
            retrievers_str = ", ".join(retrievers) if retrievers else "unknown"
            
            enhanced_query += f"| {i+1} | {doc_id} | {name} | {cwe_type} | {score:.4f} | {retrievers_str} |\n"
        
        enhanced_query += "\n"
    
    def _search_with_retry(self, description, keyphrases, cve_id):
        """
        Perform retriever search with retry logic.
        
        Args:
            description: Vulnerability description
            keyphrases: Dictionary of keyphrases
            cve_id: The CVE identifier
            
        Returns:
            Relevant CWEs from rootcause and weakness keyphrases search
        """
        from tenacity import retry, stop_after_attempt, wait_exponential
        
        @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
        def search():
            return self.kb.retriever.search(
                description,
                keyphrases=keyphrases,
                k=5,
                use_graph=True,
                use_rag=True,
                use_sparse=True,
                rerank=False,
                cve_id=cve_id
            )
            
        return search()
    

    
    
    def setup_relationship_analysis(self, cve_id: str, cve_dir: str, cve_logger):
        """
        Set up relationship analysis for a specific CVE.
        
        Args:
            cve_id: The CVE identifier
            cve_dir: The CVE output directory
            cve_logger: The CVE-specific logger
            
        Returns:
            Path to the relationship analysis directory
        """
        # Create relationship analysis subdirectory
        relationship_dir = os.path.join(cve_dir, "relationship_analysis")
        ensure_directory(relationship_dir)
        cve_logger.info(f"Created relationship analysis directory: {relationship_dir}")
        
        # Set output directory for each agent
        for agent_name, agent in self.kb.agents.items():
            # Only set if the agent is a RelationshipEnhancedLLMAgent
            if isinstance(agent, RelationshipEnhancedLLMAgent):
                agent.output_dir = relationship_dir
                cve_logger.info(f"Set relationship output directory for {agent_name} agent")
        
        return relationship_dir



    def process_analyzer_agent(self, vuln_info, enhanced_query, cve_id, cve_dir, cve_logger):
        """
        Process the vulnerability with the analyzer agent.
        
        Args:
            vuln_info: Vulnerability information object
            enhanced_query: Enhanced query text
            cve_id: CVE identifier
            cve_dir: CVE output directory
            cve_logger: CVE-specific logger
            
        Returns:
            Tuple of (analysis_text, identified_cwes, relationship_analysis)
        """
        cve_logger.info("Processing with analyzer agent")
        analyzer = self.kb.agents['analyzer']
        
        # Set up relationship analysis if using enhanced agent
        relationship_analysis = None
        if isinstance(analyzer, RelationshipEnhancedLLMAgent):
            relationship_dir = self.setup_relationship_analysis(cve_id, cve_dir, cve_logger)
            cve_logger.info("Using relationship-enhanced analyzer")
        
        # Generate response
        response = analyzer.generate_response(enhanced_query)
        
        # Handle regular response vs enhanced response
        if isinstance(response, dict) and "response" in response:
            # Enhanced agent response
            analysis_text = response["response"]
            identified_cwes = response.get("cwe_ids", [])
            relationship_analysis = response.get("relationship_analysis", {})
            
            # Store identified CWEs
            vuln_info.identified_cwes['analyzer'] = identified_cwes
            
            # Store both original and enhanced analysis if available
            vuln_info.analysis = analysis_text
            
            if relationship_analysis and relationship_analysis.get("available", False):
                # Enhanced analysis with relationship information
                enhanced_text = analyzer.enhance_response_with_relationships(
                    analysis_text, relationship_analysis
                )
                vuln_info.analysis_with_relationships = enhanced_text
                
                # Save relationship analysis separately
                save_json(
                    os.path.join(cve_dir, f"{cve_id}_relationship_analysis.json"),
                    relationship_analysis
                )
                
                # Save enhanced analysis with relationships
                save_markdown(
                    os.path.join(cve_dir, f"{cve_id}_analysis_with_relationships.md"),
                    f"Enhanced Analysis for {cve_id} with Relationship Information",
                    enhanced_text
                )
                
                cve_logger.info("Generated enhanced analysis with relationship information")
                
                # Save mermaid diagram if available
                if relationship_analysis.get("mermaid_diagram"):
                    mermaid_path = os.path.join(cve_dir, f"{cve_id}_relationships.mmd")
                    with open(mermaid_path, 'w') as f:
                        f.write(relationship_analysis["mermaid_diagram"])
                    cve_logger.info(f"Saved Mermaid diagram to {mermaid_path}")
        else:
            # Regular agent response (string)
            analysis_text = response
            identified_cwes = []  # Need to extract CWE IDs manually
            relationship_analysis = None
            
            # Extract CWE IDs from text
            import re
            cwe_pattern = re.compile(r"CWE-\d+")
            identified_cwes = list(set(cwe_pattern.findall(analysis_text)))
            
            # Store identified CWEs and analysis
            vuln_info.identified_cwes['analyzer'] = identified_cwes
            vuln_info.analysis = analysis_text
        
        # Save regular analysis regardless
        save_markdown(
            os.path.join(cve_dir, f"{cve_id}_analysis.md"),
            f"Analysis for {cve_id}",
            analysis_text
        )
        
        cve_logger.info(f"Analyzer identified {len(identified_cwes)} CWEs: {', '.join(identified_cwes)}")
        return analysis_text, identified_cwes, relationship_analysis

    
    def _get_cwe_details(self, cwe_ids):
        """
        Get detailed information for the identified CWEs.
        
        Args:
            cwe_ids: List of CWE IDs
            
        Returns:
            List of CWE details from the retriever
        """
        cwe_details = []
        for cwe_id in cwe_ids:
            # Remove "CWE-" prefix if present to get just the number
            cwe_num = cwe_id.replace("CWE-", "")
            try:
                # Get CWE details from retriever
                cwe_results = self.kb.retriever.search(
                    f"CWE-{cwe_num}",  # Ensure consistent format
                    k=1,     # We only need this specific CWE
                    use_graph=True  # Use property graph to get relationships
                )
                
                if cwe_results:
                    cwe_details.append(cwe_results[0])
            except Exception:
                pass
                
        return cwe_details
    
    def _generate_relationship_text(self, cwe_details, cve_id, cve_dir):
        """
        Generate textual and visual representation of CWE relationships.
        Handles duplicate relationships.
        
        Args:
            cwe_details: List of CWE details
            cve_id: The CVE identifier
            cve_dir: Directory for CVE files
            
        Returns:
            Text representation of relationships
        """
        # Generate Mermaid diagram
        mermaid_diagram = self._generate_cwe_relationship_diagram(cwe_details)
        
        # Save the diagram separately
        save_markdown(
            os.path.join(cve_dir, f"{cve_id}_cwe_relationships.md"),
            f"CWE Relationships for {cve_id}",
            f"```mermaid\n{mermaid_diagram}\n```"
        )
        
        # Generate textual representation of relationships
        relationship_text = "\n## CWE Relationships\n\nThe following relationships between CWEs were identified:\n\n"
        
        for cwe in cwe_details:
            metadata = cwe.get('metadata', {})
            cwe_id = metadata.get('doc_id', '')
            name = metadata.get('name', '')
            relationships = metadata.get('relationships', [])
            
            if relationships:
                relationship_text += f"### {cwe_id} - {name}\n\n"
                relationship_text += "Related to:\n\n"
                
                # Create a dictionary to track unique relationships by target ID and label
                unique_relationships = {}
                
                for rel in relationships:
                    target_id = rel.get('target_id', '')
                    label = rel.get('label', '')
                    
                    # Create a unique key for this relationship type and target
                    rel_key = f"{target_id}|{label}"
                    
                    # Only add if we haven't seen this exact relationship before
                    if rel_key not in unique_relationships:
                        unique_relationships[rel_key] = {
                            'target_id': target_id,
                            'label': label
                        }
                
                # Add each unique relationship to the text
                for rel_data in unique_relationships.values():
                    target_id = rel_data['target_id']
                    label = rel_data['label']
                    target_num = target_id.replace('CWE-', '')
                    relationship_text += f"- **{label}** → [{target_id}](https://cwe.mitre.org/data/definitions/{target_num}.html)\n"
                    
                relationship_text += "\n"
        
        # Save the relationships
        save_markdown(
            os.path.join(cve_dir, f"{cve_id}_cwe_relationship_details.md"),
            f"CWE Relationship Details for {cve_id}",
            relationship_text
        )
        
        return relationship_text
    

    def process_critic_agent(self, vuln_info, analysis, enhanced_query, cwe_ids, cve_id, cve_dir, cve_logger):
        """
        Process the vulnerability with the critic agent.
        
        Args:
            vuln_info: VulnerabilityInfo object
            analysis: Original analysis text from analyzer
            enhanced_query: Enhanced query with full vulnerability information (replacing description)
            cwe_ids: List of CWE IDs
            cve_id: The CVE identifier
            cve_dir: Directory for CVE files
            cve_logger: Logger for this CVE
            
        Returns:
            Criticism text from the critic agent
        """
        cve_logger.info("Getting criticism from critic agent")
        
        # Start with the original analysis
        enhanced_analysis = analysis
        
        # Set a default value for cwe_examples_text 
        cwe_examples_text = ""
        
        # Step 1: Generate CWE relationship diagram if CWEs were identified
        if cwe_ids:
            try:
                cve_logger.info(f"Generating CWE relationship diagram for {len(cwe_ids)} CWEs")
                cwe_details = self._get_cwe_details(cwe_ids)
                
                if cwe_details:
                    # Generate and save relationship diagram
                    relationship_text = self._generate_relationship_text(cwe_details, cve_id, cve_dir)
                    
                    # Update the analysis with relationships
                    enhanced_analysis = analysis + "\n\n" + relationship_text
                    
                    # Save the relationship-enhanced analysis
                    save_markdown(
                        os.path.join(cve_dir, f"{cve_id}_analysis_with_relationships.md"),
                        f"Analysis with CWE Relationships for {cve_id}",
                        enhanced_analysis
                    )
            except Exception as e:
                cve_logger.warning(f"Failed to generate relationship diagram: {e}")
        
        # Step 2: Get CWE example information
        try:
            # Get the CWE entries from the database - first check if they're directly accessible
            cwe_entries = getattr(self.kb, 'cwe_entries', None)
            
            # If we have entries and CWE IDs, enhance the analysis with examples
            if cwe_entries and cwe_ids:
                cve_logger.info(f"Collecting examples for {len(cwe_ids)} CWEs")
                try:
                    # Define and import the _generate_cwe_examples_text method if it's not already in your class
                    if not hasattr(self, '_generate_cwe_examples_text'):
                        cve_logger.warning("_generate_cwe_examples_text method not found, using inline implementation")
                        # Generate examples text using a simple implementation
                        examples_sections = []
                        for cwe_id in cwe_ids:
                            clean_id = cwe_id.replace("CWE-", "")
                            examples_sections.append(f"\n\n## Known Examples for CWE-{clean_id}\n\n"
                                                f"### Observed Examples\n\n"
                                                f"- **CVE-2023-EXAMPLE**: Example vulnerability for CWE-{clean_id}\n")
                        cwe_examples_text = "".join(examples_sections)
                    else:
                        # Use the proper method if it exists
                        cwe_examples_text = self._generate_cwe_examples_text(cwe_ids, cwe_entries)
                    
                    # Also create fully enhanced analysis for reference
                    fully_enhanced_analysis = enhanced_analysis + "\n\n" + cwe_examples_text
                    
                    # Save the fully enhanced analysis (relationships + examples)
                    save_markdown(
                        os.path.join(cve_dir, f"{cve_id}_analysis_fully_enhanced.md"),
                        f"Fully Enhanced Analysis for Critic Review - {cve_id}",
                        fully_enhanced_analysis
                    )
                    
                except Exception as e:
                    cve_logger.warning(f"Failed to collect examples for critic: {e}", exc_info=True)
            else:
                cve_logger.warning("No CWE entries available for enhancement or no CWE IDs identified")

        except Exception as e:
            cve_logger.warning(f"Failed to access CWE database for critic enhancement: {e}", exc_info=True)
        
        # Step 3: Prepare critic input with full CWE specifications
        cwe_specs = []
        for cwe_id in cwe_ids:
            try:
                cwe = self.kb.agents['critic']._get_cwe_details(cwe_id)
                if cwe:
                    cwe_specs.append(self.kb.agents['critic']._format_cwe_info(cwe))
            except Exception as e:
                cve_logger.warning(f"Failed to get CWE details for {cwe_id}: {e}")
        
        # Step 4: Create detailed critic input that INCLUDES the examples
        critic_input = f"""

# Original Analyzer Input
{enhanced_query}

# Analysis to Review
{enhanced_analysis}

# CWE Examples from Database
{cwe_examples_text}

# Relevant CWE Specifications
{chr(10).join(cwe_specs) if cwe_specs else "No CWE specifications provided."}"""
        
        # Save critic input including CWE specifications and examples
        save_markdown(
            os.path.join(cve_dir, f"{cve_id}_critic_input.md"),
            f"Critic Input for {cve_id}",
            critic_input
        )
        
        try:
            # Get criticism
            critic_result = self.kb.agents['critic'].generate_response(critic_input)
            criticism = critic_result["response"]
            vuln_info.criticism = criticism
            
            # Save criticism
            save_markdown(
                os.path.join(cve_dir, f"{cve_id}_criticism.md"),
                f"Criticism for {cve_id}",
                criticism
            )
            
            # Extract CWEs suggested by critic
            import re
            critic_cwe_ids = re.findall(r'CWE-\d+', criticism)
            new_cwes = set(critic_cwe_ids) - set(cwe_ids)
            vuln_info.identified_cwes['critic_additional'] = list(new_cwes)
            
            # Save additional CWEs identified by critic
            if new_cwes:
                cve_logger.info(f"Critic suggested additional CWEs: {', '.join(new_cwes)}")
                save_json(
                    os.path.join(cve_dir, f"{cve_id}_critic_additional_cwes.json"),
                    {"additional_cwe_ids": list(new_cwes)}
                )
        except Exception as e:
            cve_logger.error(f"Error in critic analysis: {e}", exc_info=True)
            criticism = f"Error during critic analysis: {str(e)}"
            vuln_info.criticism = criticism
        
        # Update vulnerabilityInfo with enhanced analysis for final resolution
        vuln_info.analysis_with_relationships = enhanced_analysis
            
        return criticism


    def _generate_cwe_examples_text(self, cwe_ids, cwe_entries):
        """
        Generate markdown text with examples for each identified CWE.
        Limited to 10 examples total across all categories.
        
        Args:
            cwe_ids: List of CWE IDs
            cwe_entries: List of CWE entries from the database
            
        Returns:
            str: Markdown formatted text with examples
        """
        import logging
        logger = logging.getLogger(__name__)
        import re
        
        # Deduplicate CWE IDs while preserving order
        unique_cwe_ids = []
        for cwe_id in cwe_ids:
            # Remove "CWE-" prefix if present
            clean_id = cwe_id.replace("CWE-", "")
            if clean_id not in unique_cwe_ids:
                unique_cwe_ids.append(clean_id)
        
        # If no CWEs found, return empty string
        if not unique_cwe_ids:
            return ""
        
        # Create a lookup of CWE entries by ID with error handling
        cwe_lookup = {}
        for entry in cwe_entries:
            try:
                # Handle potential differences in ID field name or formatting
                cwe_id = None
                if hasattr(entry, 'ID'):
                    cwe_id = entry.ID
                elif hasattr(entry, 'id'):
                    cwe_id = entry.id
                elif hasattr(entry, 'cwe_id'):
                    cwe_id = entry.cwe_id
                    
                # Sometimes the ID might be prefixed with "CWE-"
                if cwe_id and isinstance(cwe_id, str) and cwe_id.startswith("CWE-"):
                    cwe_id = cwe_id[4:]  # Remove "CWE-" prefix
                    
                if cwe_id:
                    cwe_lookup[cwe_id] = entry
            except Exception as e:
                logger.warning(f"Error processing CWE entry: {e}")
        
        # Build the examples section
        examples_sections = []
        total_examples_count = 0
        examples_limit = 10
        
        for cwe_id in unique_cwe_ids:
            # Skip if this CWE ID is not in our database
            if cwe_id not in cwe_lookup:
                logger.debug(f"CWE-{cwe_id} not found in database")
                continue
                
            cwe_entry = cwe_lookup[cwe_id]
            logger.debug(f"Processing examples for CWE-{cwe_id}")
            
            # Start building the section
            section = [f"\n\n## Known Examples for CWE-{cwe_id}: {cwe_entry.Name}\n"]
            section_examples = []
            
            # Collect all examples first
            all_examples = []
            
            # Add ObservedExamples with error handling
            try:
                observed_examples = getattr(cwe_entry, 'ObservedExamples', None)
                if observed_examples and len(observed_examples) > 0:
                    for example in observed_examples:
                        try:
                            reference = getattr(example, 'Reference', 'Unknown')
                            description = getattr(example, 'Description', 'No description available')
                            link = ""
                            if hasattr(example, 'Link') and example.Link:
                                link = f" [{example.Link}]({example.Link})"
                            all_examples.append({
                                'type': 'Observed',
                                'content': f"- **{reference}**{link}: {description}\n"
                            })
                        except Exception as e:
                            logger.warning(f"Error processing observed example: {e}")
                            continue
            except Exception as e:
                logger.warning(f"Error accessing ObservedExamples for CWE-{cwe_id}: {e}")
            
            # Add Top25Examples with robust error handling
            try:
                # Try multiple possible attribute names for Top25Examples
                top25_examples = None
                for attr_name in ['Top25Examples', 'top25_examples', 'top_25_examples', 'TopExamples']:
                    if hasattr(cwe_entry, attr_name):
                        top25_examples = getattr(cwe_entry, attr_name)
                        break
                        
                if top25_examples and len(top25_examples) > 0:
                    for example in top25_examples:
                        try:
                            reference = getattr(example, 'Reference', 'N/A')
                            description = getattr(example, 'Description', 'No description available')
                            link = ""
                            if hasattr(example, 'Link') and example.Link:
                                link = f" [{example.Link}]({example.Link})"
                            all_examples.append({
                                'type': 'Top25',
                                'content': f"- **{reference}**{link}: {description}\n"
                            })
                        except Exception as e:
                            logger.warning(f"Error processing Top25 example: {e}")
                            continue
            except Exception as e:
                logger.warning(f"Error accessing Top25Examples for CWE-{cwe_id}: {e}")
            
            # If we have examples and haven't reached the limit
            if all_examples:
                # Group examples by type
                observed = [ex for ex in all_examples if ex['type'] == 'Observed']
                top25 = [ex for ex in all_examples if ex['type'] == 'Top25']
                
                # Calculate how many examples we can add from this CWE
                remaining_examples = examples_limit - total_examples_count
                examples_to_add = min(len(all_examples), remaining_examples)
                
                if examples_to_add > 0:
                    # Add Observed Examples section if needed
                    if observed and examples_to_add > 0:
                        section.append("### Observed Examples\n")
                        # Calculate how many observed examples to include
                        observed_count = min(len(observed), examples_to_add)
                        for i in range(observed_count):
                            section.append(observed[i]['content'])
                        examples_to_add -= observed_count
                        total_examples_count += observed_count
                    
                    # Add Top 25 Examples section if needed
                    if top25 and examples_to_add > 0:
                        section.append("### Top 25 Examples\n")
                        # Calculate how many top25 examples to include
                        top25_count = min(len(top25), examples_to_add)
                        for i in range(top25_count):
                            section.append(top25[i]['content'])
                        total_examples_count += top25_count
                    
                    # Only add sections that have content beyond the heading
                    if len(section) > 1:
                        examples_sections.append("".join(section))
                
                # If we've reached the limit, stop processing further CWEs
                if total_examples_count >= examples_limit:
                    break
        
        # Return empty string if we didn't find any examples
        if not examples_sections:
            return ""
        
        # Combine all sections
        return "".join(examples_sections)
    

    
    def process_resolver_agent(self, vuln_info, analysis_with_relationships, criticism, description, cve_id, cve_dir, cve_logger):
        """
        Process the vulnerability with the resolver agent.
        
        Args:
            vuln_info: VulnerabilityInfo object
            analysis_with_relationships: Analysis text with relationships
            criticism: Criticism text from the critic agent
            description: Vulnerability description
            cve_id: The CVE identifier
            cve_dir: Directory for CVE files
            cve_logger: Logger for this CVE
            
        Returns:
            Resolution text from the resolver agent
        """
        cve_logger.info("Getting final resolution from resolver agent")
        
        # Prepare resolver input
        resolver_input = f"""# Resolution Input for {cve_id}

## Vulnerability Description
{description}

## Initial Analysis
{analysis_with_relationships}

## Criticism
{criticism}

Consider both the direct matches and the relationships between CWEs
when making your final determination.
        """
        
        # Save resolver input
        save_markdown(
            os.path.join(cve_dir, f"{cve_id}_resolver_input.md"),
            f"Resolver Input for {cve_id}",
            resolver_input
        )
        
        # Get final resolution
        resolution_result = self.kb.agents['resolver'].generate_response(resolver_input)
        resolution = resolution_result["response"]
        

        
        # Process the resolution to remove nested markdown blocks
        resolution = self.remove_nested_markdown_blocks(resolution)
        
        vuln_info.resolution = resolution
        
        # Save resolution
        save_markdown(
            os.path.join(cve_dir, f"{cve_id}_resolution.md"),
            f"Final Resolution for {cve_id}",
            resolution
        )
        
        return resolution
    
    def generate_comprehensive_report(self, cve_id, query, keyphrases=None, k=50):
        """Generate a comprehensive report showing results from each retriever separately."""
        report = {
            "query": query,
            "keyphrases": keyphrases,
            "dense_results": [],
            "sparse_results": [],
            "graph_results": []
        }
        
        # Get results from dense retriever
        try:
            dense_results = self.dense_retriever.search(query, k=k, score_threshold=0.0)  # Lower threshold to see all results
            report["dense_results"] = [
                {
                    "cwe_id": r.get("metadata", {}).get("doc_id", "unknown"),
                    "name": r.get("metadata", {}).get("name", "unknown"),
                    "score": r.get("similarity", 0.0),
                }
                for r in dense_results
            ]
        except Exception as e:
            logger.error(f"Error getting dense results: {e}")
        
        # Get results from sparse retriever
        try:
            if self.sparse_retriever:
                sparse_results = self.sparse_retriever.search(query, k=k)
                report["sparse_results"] = [
                    {
                        "cwe_id": r.get("cwe_id", "unknown"),
                        "name": r.get("name", "unknown"),
                        "score": r.get("score", 0.0),
                    }
                    for r in sparse_results
                ]
        except Exception as e:
            logger.error(f"Error getting sparse results: {e}")
        
        # Get results from graph retriever
        try:
            graph_results = self.property_graph.search(query, k=k, include_text=False)
            report["graph_results"] = [
                {
                    "cwe_id": r.get("doc_id", r.get("metadata", {}).get("doc_id", "unknown")),
                    "name": r.get("metadata", {}).get("name", "unknown"),
                    "score": r.get("similarity", 0.0),
                }
                for r in graph_results
            ]
        except Exception as e:
            logger.error(f"Error getting graph results: {e}")
        
        # Save report
        report_file = os.path.join(self.output_dir, cve_id, f"{cve_id}_comprehensive_report.json")
        save_json(report_file, report)
        
        # Generate markdown report
        md_report = f"""# Comprehensive Retrieval Results for {cve_id}

## Query
{query}

## Dense Retriever Results ({len(report["dense_results"])})
| CWE ID | Name | Score |
|--------|------|-------|
"""
        for r in report["dense_results"]:
            md_report += f"| {r['cwe_id']} | {r['name']} | {r['score']:.4f} |\n"

        # Add section for sparse retriever
        md_report += f"""
## Sparse Retriever Results ({len(report["sparse_results"])})
| CWE ID | Name | Score |
|--------|------|-------|
"""
        for r in report["sparse_results"]:
            md_report += f"| {r['cwe_id']} | {r['name']} | {r['score']:.4f} |\n"

        # Add section for graph retriever
        md_report += f"""
## Graph Retriever Results ({len(report["graph_results"])})
| CWE ID | Name | Score |
|--------|------|-------|
"""
        for r in report["graph_results"]:
            md_report += f"| {r['cwe_id']} | {r['name']} | {r['score']:.4f} |\n"

        md_file = os.path.join(self.output_dir, cve_id, f"{cve_id}_comprehensive_report.md")
        save_markdown(md_file, f"Comprehensive Retrieval Results for {cve_id}", md_report)

        return report

        
    def process_vulnerability(self, cve_id: str, description: str, summary_writer=None, cve_logger=None) -> ProcessingResult:
        """
        Updated process_vulnerability method that reflects the consolidated CWE enhancements.
        
        Args:
            cve_id: The CVE identifier
            description: Vulnerability description
            summary_writer: Optional CSV writer for summary
            cve_logger: Optional dedicated logger
            
        Returns:
            ProcessingResult with processing status and details
        """
        cve_dir = os.path.join(self.output_dir, cve_id)
        ensure_directory(cve_dir)
        
        # Clear any existing error file
        error_file_path = os.path.join(cve_dir, f"{cve_id}_error.md")
        if os.path.exists(error_file_path):
            try:
                os.remove(error_file_path)
            except Exception as e:
                logger.warning(f"Failed to remove old error file for {cve_id}: {e}")
        
        # Track if we created a new logger
        created_logger = False
        if cve_logger is None:
            cve_logger = self.setup_cve_logger(cve_id)
            created_logger = True
        
        # Use consistent logger prefixes
        cve_logger.info(f"[{cve_id}] Starting processing")
        logger.info(f"[{cve_id}] Processing...")
        
        start_time = time.time()
        
        try:
            # Step 1: Prepare vulnerability information and enhanced query
            vuln_info, enhanced_query = self.prepare_vulnerability_info(cve_id, description, cve_logger)
            
            # Save the enhanced query for reference
            save_markdown(
                os.path.join(cve_dir, f"{cve_id}_analyzer_input.md"),
                f"Vulnerability Information: {cve_id}",
                enhanced_query
            )
            
            # Generate and save comprehensive report of retriever results
            if hasattr(self.kb, 'retriever') and hasattr(self.kb.retriever, 'generate_comprehensive_report'):
                try:
                    cve_logger.info("Generating comprehensive retriever report...")
                    comprehensive_report = self.kb.retriever.generate_comprehensive_report(
                        cve_id, 
                        description, 
                        vuln_info.key_phrases,
                        k=50  #TOOD
                    )
                    cve_logger.info(f"Generated comprehensive retriever report with results from all retrievers")
                except Exception as e:
                    cve_logger.warning(f"Failed to generate comprehensive report: {e}")
            
            # Step 2: Process with analyzer agent
            analysis, cwe_ids, relationship_analysis = self.process_analyzer_agent(
                vuln_info, enhanced_query, cve_id, cve_dir, cve_logger
            )
            
            # Log token usage for analyzer
            self.log_token_usage(cve_id, "analyzer", enhanced_query, analysis)
            
            # Step 3: Process with critic agent
            criticism = self.process_critic_agent(
                vuln_info, analysis, enhanced_query, cwe_ids, 
                cve_id, cve_dir, cve_logger
            )
            
            # Get the critic input for token logging
            critic_input_file = os.path.join(cve_dir, f"{cve_id}_critic_input.md")
            critic_input = ""
            if os.path.exists(critic_input_file):
                with open(critic_input_file, 'r') as f:
                    critic_input = f.read()
            
            # Log token usage for critic
            self.log_token_usage(cve_id, "critic", critic_input, criticism)
            
            # Step 4: Process with resolver agent
            enhanced_analysis = vuln_info.analysis_with_relationships if hasattr(vuln_info, 'analysis_with_relationships') else analysis
            resolution = self.process_resolver_agent(
                vuln_info, enhanced_analysis, criticism, description, 
                cve_id, cve_dir, cve_logger
            )
            
            # Get the resolver input for token logging
            resolver_input_file = os.path.join(cve_dir, f"{cve_id}_resolver_input.md")
            resolver_input = ""
            if os.path.exists(resolver_input_file):
                with open(resolver_input_file, 'r') as f:
                    resolver_input = f.read()
            
            # Log token usage for resolver
            self.log_token_usage(cve_id, "resolver", resolver_input, resolution)
            
            # Step 5: Save keyphrase information
            if vuln_info.key_phrases:
                keyphrases = {}
                if vuln_info.key_phrases.get('rootcause'):
                    keyphrases['rootcause'] = vuln_info.key_phrases['rootcause']
                if vuln_info.key_phrases.get('weakness'):
                    keyphrases['weakness'] = vuln_info.key_phrases['weakness']
                    
                save_json(
                    os.path.join(cve_dir, f"{cve_id}_keyphrases.json"),
                    {"keyphrases": keyphrases}
                )
            
            # Step 6: Save retriever results
            if vuln_info.relevant_cwes:
                save_json(
                    os.path.join(cve_dir, f"{cve_id}_retriever_results.json"),
                    {
                        "keyphrases_used": {
                            "rootcause": vuln_info.key_phrases.get('rootcause', ''),
                            "weakness": vuln_info.key_phrases.get('weakness', '')
                        },
                        "relevant_cwes": [
                            {
                                "doc_id": cwe["metadata"]["doc_id"],
                                "name": cwe["metadata"].get("name", ""),
                                "similarity": cwe.get("similarity", 0.0),
                                "relationships": cwe["metadata"].get("relationships", [])
                            } for cwe in vuln_info.relevant_cwes
                        ]
                    }
                )
            
            # Step 7: Generate final report
            report = self.generate_markdown_report(vuln_info)
            save_markdown(
                os.path.join(cve_dir, f"{cve_id}_report.md"),
                f"Analysis Report for {cve_id}",
                report
            )
            
            # Step 8: Save full analysis results as JSON
            save_json(
                os.path.join(cve_dir, f"{cve_id}_analysis.json"), 
                vuln_info.to_dict()
            )
            
            # Log detected CWEs
            detected_cwes = vuln_info.detected_cwes
            cwe_list_str = ', '.join(detected_cwes) if detected_cwes else 'None'
            cve_logger.info(f"Detected CWEs: {cwe_list_str}")
            
            # Record processing time and update summary
            processing_time = time.time() - start_time
            if summary_writer:
                summary_writer.writerow([
                    cve_id,
                    "|".join(detected_cwes),
                    f"{processing_time:.2f}"
                ])
            
            # Use the standard logger methods that exist in both loggers
            logger.info(f"Successfully processed {cve_id} in {processing_time:.2f} seconds")
            cve_logger.info(f"Processing completed in {processing_time:.2f} seconds")
            
            # If you want to use loguru's success method, use it directly:
            loguru_logger.success(f"Successfully processed {cve_id} in {processing_time:.2f} seconds")
            
            # Clean up the logger if we created it
            if created_logger:
                self.cleanup_cve_logger(cve_logger)
            
            # Return success result
            return ProcessingResult(
                cve_id=cve_id,
                status="success",
                vulnerability_info=vuln_info,
                processing_time=processing_time
            )
            
        except Exception as e:
            import traceback
            error_msg = f"Error processing {cve_id}: {str(e)}"
            logger.error(error_msg)
            cve_logger.error(error_msg, exc_info=True)
            
            # Create the error file only when an error occurs
            # Using 'w' mode to ensure it's created fresh each time
            error_traceback = traceback.format_exc()
            save_markdown(
                os.path.join(cve_dir, f"{cve_id}_error.md"),
                f"Processing Error for {cve_id}",
                f"# Error Processing {cve_id}\n\n"
                f"Time: {datetime.now().isoformat()}\n\n"
                f"## Error Message\n\n{error_msg}\n\n"
                f"## Traceback\n\n```\n{error_traceback}\n```"
            )
            
            if summary_writer:
                summary_writer.writerow([cve_id, "ERROR", "0.00"])
                
            # Clean up the logger if we created it
            if created_logger:
                self.cleanup_cve_logger(cve_logger)
                
            return ProcessingResult(
                cve_id=cve_id,
                status="error",
                error=str(e)
            )
    
    def log_token_usage(self, cve_id, stage, input_text, output_text):
        """
        Log token usage statistics for a given agent stage.
        
        Args:
            cve_id: The CVE identifier
            stage: The processing stage (analyzer, critic, resolver)
            input_text: The input text sent to the agent
            output_text: The output text received from the agent
        """
        # Calculate simple token estimates (rough approximation using words)
        input_words = len(input_text.split())
        output_words = len(output_text.split())
        
        # Create log entry
        entry = {
            "cve_id": cve_id,
            "stage": stage,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "input_length": len(input_text),
            "input_words": input_words,
            "output_length": len(output_text),
            "output_words": output_words
        }
        
        # Ensure the token usage file exists and has headers
        token_log_path = os.path.join(self.output_dir, "token_usage.csv")
        file_exists = os.path.isfile(token_log_path)
        
        # Write to CSV
        with open(token_log_path, 'a', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=list(entry.keys()))
            if not file_exists:
                writer.writeheader()
            writer.writerow(entry)
            
        # Log the information
        logger.debug(f"[{cve_id}] {stage.capitalize()} token usage - Input: {input_words} words, Output: {output_words} words")
        
        # Return the entry for potential further processing
        return entry    
    
    def _generate_cwe_relationship_diagram(self, cwe_details):
        """
        Generate a Mermaid diagram for CWE relationships.
        Handles duplicate relationships.
        
        Args:
            cwe_details: List of CWE details
            
        Returns:
            str: Mermaid diagram code
        """
        # Create nodes and connections
        nodes = {}
        connections = set()  # Use a set to prevent duplicate connections
        all_related_cwes = set()
        
        # Process top CWEs
        for i, cwe in enumerate(cwe_details):
            metadata = cwe.get('metadata', {})
            cwe_id = metadata.get('doc_id', '')
            name = metadata.get('name', '')
            
            if not cwe_id:
                continue
                
            # Clean up CWE name for display
            if len(name) > 25:
                name = name[:22] + "..."
                
            # Create node ID and label
            node_id = f"cwe{cwe_id.replace('CWE-', '')}"
            node_label = f"{cwe_id}: {name}"
            nodes[cwe_id] = {
                'id': node_id,
                'label': node_label,
                'class': 'primary' if i == 0 else 'secondary'
            }
            
            # Track unique relationships by combination of source, target, and label
            unique_relationships = set()
            
            # Process relationships
            relationships = metadata.get('relationships', [])
            for rel in relationships:
                source_id = rel.get('source_id', '') or cwe_id
                target_id = rel.get('target_id', '')
                label = rel.get('label', '')
                
                if not (source_id and target_id and label):
                    continue
                    
                # Create a unique key for this relationship
                rel_key = f"{source_id}|{label}|{target_id}"
                
                # Skip if we've already processed this exact relationship
                if rel_key in unique_relationships:
                    continue
                    
                unique_relationships.add(rel_key)
                
                source_node_id = f"cwe{source_id.replace('CWE-', '')}"
                target_node_id = f"cwe{target_id.replace('CWE-', '')}"
                
                # Add relationship to connections set (automatically deduplicates)
                connections.add((source_node_id, label, target_node_id))
                
                # Track related CWEs to include in diagram
                if target_id != cwe_id and target_id not in nodes:
                    all_related_cwes.add(target_id)
        
        # Add nodes for related CWEs
        for related_cwe in all_related_cwes:
            if related_cwe not in nodes:
                # Find CWE name if available
                name = "Unknown"
                for cwe in cwe_details:
                    if cwe.get('metadata', {}).get('doc_id', '') == related_cwe:
                        name = cwe.get('metadata', {}).get('name', "Unknown")
                        break
                        
                if len(name) > 25:
                    name = name[:22] + "..."
                    
                node_id = f"cwe{related_cwe.replace('CWE-', '')}"
                node_label = f"{related_cwe}: {name}"
                nodes[related_cwe] = {
                    'id': node_id,
                    'label': node_label,
                    'class': 'tertiary'
                }
        
        # Build Mermaid diagram
        diagram = "graph TD\n"
        
        # Add nodes
        for cwe_id, node in nodes.items():
            diagram += f"    {node['id']}[\"{node['label']}\"]\n"
        
        # Add connections
        for source, label, target in connections:
            diagram += f"    {source} -->|{label}| {target}\n"
        
        # Add styling
        diagram += "    classDef primary fill:#f96,stroke:#333,stroke-width:2px\n"
        diagram += "    classDef secondary fill:#69f,stroke:#333\n"
        diagram += "    classDef tertiary fill:#9e9,stroke:#333\n"
        
        # Apply classes
        for cwe_id, node in nodes.items():
            diagram += f"    class {node['id']} {node['class']};\n"
        
        return diagram
    
    def _add_cwe_visualizations(self, info: VulnerabilityInfo, report: str) -> str:
        """Add CWE relationship visualizations to the report for only the final selected CWEs.
        
        Args:
            info: VulnerabilityInfo object containing analysis results
            report: Current markdown report string
            
        Returns:
            str: Updated report with visualizations added
        """
        # Check if we have resolution and identified CWEs
        if not info.resolution or not info.identified_cwes:
            return report
        
        # Extract CWE-IDs from the resolver's final decision
        # This regex finds all CWE-XXX patterns in the resolution text
        import re
        final_cwe_ids = set(re.findall(r'CWE-\d+', info.resolution))
        
        if not final_cwe_ids:
            # If no CWEs were found in the resolution text, 
            # check if they're stored in the identified_cwes dictionary
            for category, cwe_list in info.identified_cwes.items():
                for cwe_id in cwe_list:
                    if cwe_id.startswith("CWE-"):
                        final_cwe_ids.add(cwe_id)
        
        if not final_cwe_ids:
            return report
        
        # Get full details for the final CWEs
        final_cwes = []
        for cwe in info.relevant_cwes:
            if 'metadata' in cwe and 'doc_id' in cwe['metadata']:
                doc_id = cwe['metadata']['doc_id']
                if doc_id in final_cwe_ids:
                    final_cwes.append({
                        'id': doc_id,
                        'name': cwe['metadata'].get('name', ""),
                        'score': cwe.get('similarity', 0.0),
                        'relationships': cwe['metadata'].get('relationships', [])
                    })
        
        # Generate Mermaid Diagram Section
        visualization_section = "\n## Selected CWE Relationships\n\n"
        visualization_section += "The relationships between the final selected CWEs can be visualized as follows:\n\n"
        
        # Start Mermaid Graph
        mermaid_diagram = "```mermaid\ngraph TD\n"
        
        # Create nodes and connections
        nodes = {}
        connections = []
        all_related_cwes = set()
        
        # First, create nodes for the selected CWEs
        for i, cwe in enumerate(final_cwes):
            cwe_id = cwe['id']
            # Clean up CWE name for display (truncate if too long)
            name = cwe['name']
            if len(name) > 25:
                name = name[:22] + "..."
                
            # Create node ID and label
            node_id = f"cwe{cwe_id.replace('CWE-', '')}"  # e.g., cwe787 instead of cwe-787
            node_label = f"{cwe_id}: {name}"
            nodes[cwe_id] = {
                'id': node_id,
                'label': node_label,
                'class': 'primary' if i == 0 else 'secondary'
            }
            
            # Process relationships for this CWE
            for rel in cwe.get('relationships', []):
                source_id = rel.get('source_id')
                target_id = rel.get('target_id')
                label = rel.get('label')
                
                if not (source_id and target_id and label):
                    continue
                    
                # Add relationships relevant to our selected CWEs
                if source_id == cwe_id and target_id in final_cwe_ids:
                    target_node_id = f"cwe{target_id.replace('CWE-', '')}"
                    connections.append((node_id, label, target_node_id))
                elif target_id == cwe_id and source_id in final_cwe_ids:
                    source_node_id = f"cwe{source_id.replace('CWE-', '')}"
                    connections.append((source_node_id, label, node_id))
                # Add key related CWEs even if they weren't in final selection
                elif source_id == cwe_id and target_id not in final_cwe_ids:
                    related_cwe = target_id
                    target_node_id = f"cwe{target_id.replace('CWE-', '')}"
                    connections.append((node_id, label, target_node_id))
                    all_related_cwes.add(related_cwe)
        
        # Add nodes for important related CWEs that aren't in our selected list
        for related_cwe in all_related_cwes:
            if related_cwe not in nodes:
                # Find the name for this CWE if available
                name = "Unknown"
                for cwe in info.relevant_cwes:
                    if 'metadata' in cwe and cwe['metadata'].get('doc_id') == related_cwe:
                        name = cwe['metadata'].get('name', "Unknown")
                        break
                        
                if len(name) > 25:
                    name = name[:22] + "..."
                    
                node_id = f"cwe{related_cwe.replace('CWE-', '')}"
                node_label = f"{related_cwe}: {name}"
                nodes[related_cwe] = {
                    'id': node_id,
                    'label': node_label,
                    'class': 'tertiary'
                }
        
        # Build the actual Mermaid syntax
        for cwe_id, node in nodes.items():
            mermaid_diagram += f"    {node['id']}[\"{node['label']}\"]\n"
        
        for source, label, target in connections:
            mermaid_diagram += f"    {source} -->|{label}| {target}\n"
        
        # Add styling
        mermaid_diagram += "    classDef primary fill:#f96,stroke:#333,stroke-width:2px\n"
        mermaid_diagram += "    classDef secondary fill:#69f,stroke:#333\n"
        mermaid_diagram += "    classDef tertiary fill:#9e9,stroke:#333\n"
        
        # Apply classes
        for cwe_id, node in nodes.items():
            mermaid_diagram += f"    class {node['id']} {node['class']};\n"
        
        # Close Mermaid diagram
        mermaid_diagram += "```\n\n"
        
        # Add diagram to report only if we have nodes and connections
        if nodes and connections:
            visualization_section += mermaid_diagram
            return report + visualization_section
        
        return report
    
    def _generate_markdown_report(self, info: VulnerabilityInfo) -> str:
        """Generate detailed markdown report for vulnerability information.
        
        Args:
            info: VulnerabilityInfo object containing analysis results
            
        Returns:
            str: Formatted markdown report
        """
        report = f"# Vulnerability Analysis Report: {info.cve_id}\n\n"
        
        # Description and Key Phrases
        report += "## Description\n\n"
        report += f"{info.description}\n\n"
        
        if info.key_phrases and any(info.key_phrases.values()):
            report += "## Vulnerability Description Key Phrases\n\n"
            for key, phrase in info.key_phrases.items():
                if phrase:
                    report += f"**{key.capitalize()}:** {phrase}\n"
            report += "\n"
        
        # Analysis sections - prefer enhanced analysis with relationships if available
        if hasattr(info, 'analysis_with_relationships') and info.analysis_with_relationships:
            report += "## Analysis (with Relationship Data)\n\n"
            report += f"{info.analysis_with_relationships}\n\n"
        elif info.analysis:
            report += "## Analysis\n\n"
            report += f"{info.analysis}\n\n"
            
        if info.criticism:
            report += "## Criticism of Analysis\n\n"
            report += f"{info.criticism}\n\n"
            
        if info.resolution:
            # Process the resolution to remove nested markdown blocks
            resolution = self.remove_nested_markdown_blocks(info.resolution)
            report += "## Final Resolution\n\n"
            report += f"{resolution}\n\n"
        
        # Only add CWE visualizations if not already included in enhanced analysis
        if not hasattr(info, 'analysis_with_relationships') and info.relevant_cwes:
            report = self._add_cwe_visualizations(info, report)
        
        report += f"\n\n*Report generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"
        return report

    def _generate_analysis_template(self, info: VulnerabilityInfo) -> str:
        """Generate the analysis template with CWE retrieval scores.
        
        Args:
            info: VulnerabilityInfo object containing vulnerability data
            
        Returns:
            str: Formatted template for the analyzer
        """
        # Load analysis template
        template_path = Path(__file__).parent.parent / "prompts" / "analysis_template.txt"
        if not template_path.exists():
            logger.error(f"Required template file not found: {template_path}")
            raise FileNotFoundError(f"Required template file not found: {template_path}")
            
        with open(template_path, "r") as f:
            template = f.read().strip()
        
        # Check if template uses the new format with retrieved_cwes_table
        if '{retrieved_cwes_table}' in template:
            # Create the CWE table content
            retrieved_cwes_table = ""
            relevant_cwes = []
            
            for cwe in info.relevant_cwes:
                if 'metadata' in cwe and 'doc_id' in cwe['metadata']:
                    doc_id = cwe['metadata']['doc_id']
                    name = cwe['metadata'].get('name', "")
                    score = cwe.get('similarity', 0.0)
                    relevant_cwes.append({
                        'id': doc_id,
                        'name': name,
                        'score': score
                    })
            
            # Sort by relevance score
            relevant_cwes.sort(key=lambda x: x['score'], reverse=True)
            
            # Create CWE table rows
            for cwe in relevant_cwes:
                cwe_num = cwe['id'].replace('CWE-', '')
                retrieved_cwes_table += f"| [CWE-{cwe_num}](https://cwe.mitre.org/data/definitions/{cwe_num}.html) | {cwe['name']} | {cwe['score']:.2f} |\n"
            
            # Format template with the table
            return template.format(
                role_prompt=self.role_prompts["analyzer"],
                context=self._build_enhanced_context(info.relevant_cwes),
                retrieved_cwes_table=retrieved_cwes_table,
                input_text=info.description
            )
        else:
            # Use original template format without retrieved_cwes_table
            return template.format(
                role_prompt=self.role_prompts["analyzer"],
                context=self._build_enhanced_context(info.relevant_cwes),
                input_text=info.description
            )
            
 

    def _get_cwe_title_and_abstraction(self, cwe_num: str) -> Dict[str, str]:
        """Get the title and abstraction level for a CWE."""
        # First try to get from the cwe_entries if available
        if hasattr(self, 'kb') and hasattr(self.kb, 'cwe_entries'):
            for entry in self.kb.cwe_entries:
                if entry.ID == cwe_num:
                    return {
                        "title": entry.Name,
                        "abstraction": entry.Abstraction
                    }
        
        # If not found or not available, return unknown
        return {
            "title": "Unknown",
            "abstraction": "Unknown"
        }            
            


class CSVVulnerabilityProcessor(VulnerabilityProcessor):
    """Processes vulnerabilities from CSV files."""
    
    def __init__(self, kb, output_dir: str, config: ConfigManager):
        """Initialize the processor."""
        super().__init__(kb, output_dir, config)
    
    # Add the missing generate_markdown_report method by inheriting from parent class
    def generate_markdown_report(self, info: VulnerabilityInfo) -> str:
        """Generate markdown report by calling parent class method."""
        return super()._generate_markdown_report(info)


    def process_csv(self, csv_path: str) -> Dict[str, Any]:
        """
        Process all vulnerabilities in a CSV file.
        
        Args:
            csv_path: Path to the CSV file containing CVE IDs
            
        Returns:
            Dictionary with processing statistics
        """
                
        # Reset main logger to use a fresh file
        main_log_file = os.path.join(self.output_dir, "processing_main.log")
        
        # Remove all existing handlers from the root logger
        root_logger = logging.getLogger()
        for handler in root_logger.handlers[:]:
            root_logger.removeHandler(handler)
        
        # Add a new file handler with mode='w'
        main_handler = logging.FileHandler(main_log_file, mode='w')
        main_formatter = logging.Formatter('%(asctime)s | %(levelname)-8s | %(message)s', '%Y-%m-%d %H:%M:%S')
        main_handler.setFormatter(main_formatter)
        root_logger.addHandler(main_handler)

        summary_path = os.path.join(self.output_dir, "results_summary.csv")
        summary_header = ["CVE_ID", "Detected_CWEs", "Processing_Time"]
        processed_count = 0
        error_count = 0
        
        try:
            # Create summary file
            with open(summary_path, 'w', newline='') as summary_file:
                summary_writer = csv.writer(summary_file)
                summary_writer.writerow(summary_header)
                
                # Read and process CSV file - only require CVE_ID column
                rows = read_csv(csv_path, required_fields=['CVE_ID'])
                
                for row in rows:
                    cve_id = row['CVE_ID']
                    
                    if not cve_id:
                        logger.warning(f"Skipping row with missing CVE ID")
                        continue
                    
                    try:
                        # Get description from the JSON file directly
                        from utils.get_vulnerability_info import get_vulnerability_description
                        description = get_vulnerability_description(
                            cve_id, 
                            self.config.config.data_sources['cve_info_path']
                        )
                        
                        if not description:
                            logger.warning(f"No description found for {cve_id}, skipping")
                            continue
                            
                        # Process vulnerability
                        result = self.process_vulnerability(
                            cve_id=cve_id,
                            description=description,
                            summary_writer=summary_writer
                        )
                        
                        if result.is_success:
                            processed_count += 1
                        else:
                            error_count += 1
                            
                        # Add a small delay to avoid rate limiting
                        time.sleep(1)
                        
                    except Exception as e:
                        error_count += 1
                        logger.error(f"Error processing {cve_id}: {str(e)}")
                        continue
            
       
            logger.info(f"CSV processing complete. Successfully processed {processed_count} vulnerabilities with {error_count} errors.")
            
            return {
                "processed_count": processed_count,
                "error_count": error_count,
                "output_directory": self.output_dir
            }
            
        except Exception as e:
            logger.error(f"Error processing CSV file: {str(e)}")
            raise
        
    
    def debug_dense_retriever(self, query):
        """
        Debug function to test dense retriever directly.
        
        Args:
            query: The query text to test with
            
        Returns:
            List of results from the dense retriever
        """
        try:
            logger.info(f"Starting dense retriever debug with query: {query[:50]}...")
            
            # Check if embeddings can be generated
            try:
                logger.debug("Testing embedding generation...")
                embedding = self.kb.embedding_model.embed_query(query)
                if embedding:
                    logger.info(f"✓ Successfully generated embedding of dimension {len(embedding)}")
                else:
                    logger.error("✗ Embedding generation returned None or empty embedding")
            except Exception as embed_error:
                logger.error(f"✗ Embedding generation failed: {embed_error}")
            
            # Check if the dense retriever is available
            if not hasattr(self.kb.retriever, "dense_retriever"):
                logger.error("✗ Dense retriever not found in kb.retriever")
                return []
                
            # Try a direct search with the dense retriever
            try:
                logger.debug("Testing direct dense retriever search...")
                results = self.kb.retriever.dense_retriever.search(query, k=5)
                
                if results:
                    logger.info(f"✓ Direct dense search returned {len(results)} results")
                    for i, result in enumerate(results):
                        doc_id = result.get('metadata', {}).get('doc_id', 'unknown')
                        score = result.get('similarity', 0)
                        name = result.get('metadata', {}).get('name', 'unknown')
                        logger.info(f"  Result {i+1}: CWE-{doc_id} - {name} - Score: {score:.4f}")
                else:
                    logger.warning("! Direct dense search returned no results")
            except Exception as search_error:
                logger.error(f"✗ Direct dense search failed: {search_error}")
                
            # Try the search through the full retriever
            try:
                logger.debug("Testing dense retrieval through main retriever...")
                results = self.kb.retriever.search(
                    query,
                    keyphrases={},
                    k=5,
                    use_graph=False,
                    use_rag=True,
                    use_sparse=False,
                    rerank=False
                )
                
                if results:
                    logger.info(f"✓ Main retriever dense search returned {len(results)} results")
                    for i, result in enumerate(results):
                        doc_id = result.get('metadata', {}).get('doc_id', 'unknown')
                        score = result.get('similarity', 0)
                        name = result.get('metadata', {}).get('name', 'unknown')
                        logger.info(f"  Result {i+1}: CWE-{doc_id} - {name} - Score: {score:.4f}")
                else:
                    logger.warning("! Main retriever dense search returned no results")
            except Exception as main_error:
                logger.error(f"✗ Main retriever dense search failed: {main_error}")
            
            # Check Qdrant collection status if possible
            try:
                logger.debug("Checking Qdrant collection status...")
                collection_info = self.kb.retriever.dense_retriever.client.get_collection(
                    self.kb.retriever.dense_retriever.collection_name
                )
                logger.info(f"✓ Qdrant collection '{self.kb.retriever.dense_retriever.collection_name}' exists")
                logger.info(f"  Points count: {collection_info.points_count}")
                logger.info(f"  Vector size: {collection_info.config.params.vectors.size}")
            except Exception as collection_error:
                logger.error(f"✗ Failed to get Qdrant collection info: {collection_error}")
            
            return results
        except Exception as e:
            logger.error(f"Dense retriever debug failed: {e}")
            return []
        
        