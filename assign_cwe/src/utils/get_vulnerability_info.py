# src/utils/get_vulnerability_info.py

"""
Utility functions for retrieving vulnerability information from CVE files.
"""

import os
import json
from typing import Dict, List, Optional, Tuple
from pathlib import Path

import gzip
import csv
from typing import Dict, List, Any
from utils.logger import get_logger
from config.settings import ConfigManager
import ast
from collections import defaultdict

logger = get_logger(__name__)


from utils.cve_path_utils import (
    get_cve_path,
    read_cve_file,
    get_reference_path,
    read_reference_file
)
from utils.logger import get_logger

logger = get_logger(__name__)

def get_vulnerability_description(cve_id: str, cve_info_path: str) -> str:
    """
    Retrieves the vulnerability description for a given CVE ID.
    
    Args:
        cve_id: The CVE identifier
        cve_info_path: Base path to CVE information files
        
    Returns:
        str: Description of the vulnerability
    """
    try:
        # Get path to CVE file
        file_path = get_cve_path(cve_info_path, cve_id)
        
        # Read CVE file
        cve_data = read_cve_file(file_path)
        if not cve_data:
            logger.warning(f"No CVE file found for {cve_id}")
            return ""
        
        # Extract description
        description = cve_data.get('description', '')
        if not description:
            logger.warning(f"No description found in CVE file for {cve_id}")
            
        return description
        
    except Exception as e:
        logger.error(f"Error getting description for {cve_id}: {str(e)}")
        return ""

def get_vulnerability_reference_content(cve_id: str, cve_refs_path: str) -> Optional[str]:
    """
    Retrieves the reference content from refined.md if it exists.
    
    Args:
        cve_id: The CVE identifier
        cve_refs_path: Base directory for reference content
        
    Returns:
        Optional[str]: Content of refined.md or None if file doesn't exist
    """
    try:
        # Get path to reference file using the config-based reference path
        file_path = get_reference_path(cve_refs_path, cve_id)
        logger.debug(f"Looking for reference content at: {file_path}")
        
        # Read reference file
        content = read_reference_file(file_path)
        if content is None:
            logger.debug(f"No reference content found for {cve_id} at {file_path}")
            return None
            
        logger.debug(f"Found reference content for {cve_id}: {len(content)} characters")
        return content
        
    except Exception as e:
        logger.error(f"Error getting reference content for {cve_id}: {str(e)}")
        return None

def get_vulnerability_key_phrases(cve_id: str, cve_info_path: str) -> Dict[str, str]:
    """
    Extracts key phrases from the vulnerability file.
    
    Args:
        cve_id: The CVE identifier
        cve_info_path: Base path to CVE information files
        
    Returns:
        Dict[str, str]: Dictionary of key phrases by category
    """
    try:
        # Get path to CVE file
        file_path = get_cve_path(cve_info_path, cve_id)
        
        # Read CVE file
        cve_data = read_cve_file(file_path)
        if not cve_data:
            logger.warning(f"No CVE file found for {cve_id}")
            return {}
        
        # Extract keyphrases
        keyphrases = cve_data.get('keyphrases', {})
        if not keyphrases:
            logger.warning(f"No keyphrases found in CVE file for {cve_id}")
        
        return keyphrases
        
    except Exception as e:
        logger.error(f"Error getting keyphrases for {cve_id}: {str(e)}")
        return {}


def get_similar_cve_info(cve_id: str, output_dir: str = None, weakness: str = "", rootcause: str = "") -> Dict[str, Any]:
    """
    Get information about similar CVEs from the similarity CSV file.
    
    The CSV format is expected to be:
    CVE_ID, similarity_threshold, CWE_list, total_count, frequency, proportion
    
    Args:
        cve_id: The CVE identifier (e.g., 'CVE-2021-0896')
        output_dir: Optional path to store similarity data files
        weakness: Optional weakness type to match
        rootcause: Optional root cause to match
        
    Returns:
        Dict containing similar CVE information with the following structure:
        {
            'cwe_distribution': Dict[str, Dict],  # Distribution of CWEs at different thresholds
            'cwe_consensus': str,                 # Most common CWE across all thresholds
            'similarity_stats': Dict[str, Any]    # Statistics about similarity scores
        }
    """
    try:
        # Get config for similarity file path
        config = ConfigManager()
        similarity_path = config.config.data_sources.get('cwe_similarity_path')
        if not similarity_path:
            logger.warning("CVE similarity path not configured")
            return _empty_result()

        # Initialize data structures
        cwe_distribution = {}  # Organize by similarity threshold
        total_cwe_counts = defaultdict(int)  # Overall CWE counts
        max_freq_by_threshold = {}  # Track highest frequency at each threshold
        raw_matches = []  # Store raw matches for saving to file

        # Read and process the data
        matches_found = False
        logger.info(f"Searching for similar CVEs for {cve_id}")
        
        with gzip.open(similarity_path, 'rt') if similarity_path.endswith('.gz') else open(similarity_path, 'r') as f:
            reader = csv.reader(f)
            for row in reader:
                if row[0] == cve_id:
                    if not matches_found:
                        matches_found = True
                        logger.info(f"Found matches for {cve_id}, processing similarity data...")
                    similarity = int(row[1])
                    try:
                        cwes = ast.literal_eval(row[2])  # Parse the CWE list string
                    except:
                        cwes = []
                    total = int(row[3])
                    frequency = int(row[4])
                    proportion = float(row[5])
                    
                    # Store raw match data
                    raw_matches.append({
                        'similarity': similarity,
                        'cwes': cwes,
                        'total': total,
                        'frequency': frequency,
                        'proportion': proportion
                    })

                    # Initialize threshold data if needed
                    if similarity not in cwe_distribution:
                        cwe_distribution[similarity] = {
                            'cwe_counts': defaultdict(int),
                            'total_samples': total,
                            'distribution': []
                        }

                    # Update CWE counts and distribution
                    if isinstance(cwes, list):
                        for cwe in cwes:
                            cwe_str = f"CWE-{cwe}"
                            cwe_distribution[similarity]['cwe_counts'][cwe_str] += frequency
                            total_cwe_counts[cwe_str] += frequency

                    # Add to distribution list
                    entry = {
                        'cwes': [f"CWE-{cwe}" for cwe in cwes] if cwes else [],
                        'frequency': frequency,
                        'proportion': proportion
                    }
                    cwe_distribution[similarity]['distribution'].append(entry)

        # Calculate the consensus CWE (most frequent across all thresholds)
        cwe_consensus = max(total_cwe_counts.items(), key=lambda x: x[1])[0] if total_cwe_counts else ''

        # Calculate similarity statistics
        similarity_stats = {
            'thresholds': sorted(cwe_distribution.keys(), reverse=True),
            'total_samples_by_threshold': {
                threshold: data['total_samples']
                for threshold, data in cwe_distribution.items()
            },
            'top_cwes_by_threshold': {
                threshold: sorted(
                    data['cwe_counts'].items(),
                    key=lambda x: x[1],
                    reverse=True
                )[:3]  # Top 3 CWEs at each threshold
                for threshold, data in cwe_distribution.items()
            }
        }

        if not matches_found:
            logger.warning(f"No matches found for {cve_id} in similarity file")
            result = _empty_result()
        else:
            logger.info(f"Processed similarity data for {cve_id} across {len(cwe_distribution)} thresholds")
            logger.debug(f"CWE consensus: {cwe_consensus}")
            result = {
                'cwe_distribution': cwe_distribution,
                'cwe_consensus': cwe_consensus,
                'similarity_stats': similarity_stats,
                'raw_matches': raw_matches  # Include raw matches in the result
            }
        
        # Store the similarity data if output_dir is provided
        if output_dir and matches_found:
            try:
                # Create CVE directory if it doesn't exist
                cve_dir = os.path.join(output_dir, cve_id)
                os.makedirs(cve_dir, exist_ok=True)
                
                # Save raw matches as CSV
                csv_path = os.path.join(cve_dir, f"{cve_id}_similar_cves.csv")
                with open(csv_path, 'w', newline='') as f:
                    writer = csv.writer(f)
                    writer.writerow(['Similarity', 'CWEs', 'Total', 'Frequency', 'Proportion'])
                    for match in raw_matches:
                        writer.writerow([
                            match['similarity'],
                            match['cwes'],
                            match['total'],
                            match['frequency'],
                            match['proportion']
                        ])
                
                # Save processed similarity data as JSON
                json_path = os.path.join(cve_dir, f"{cve_id}_similarity_data.json")
                with open(json_path, 'w') as f:
                    json.dump(result, f, indent=2, default=str)
                
                logger.info(f"Saved similarity data for {cve_id} to {json_path}")
            except Exception as e:
                logger.error(f"Error saving similarity data for {cve_id}: {str(e)}")
        
        return result

    except Exception as e:
        logger.error(f"Error getting similar CVE info for {cve_id}: {str(e)}")
        return _empty_result()
    
def _empty_result() -> Dict[str, Any]:
    """Return an empty result structure."""
    return {
        'cwe_distribution': {},
        'cwe_consensus': '',
        'similarity_stats': {
            'thresholds': [],
            'total_samples_by_threshold': {},
            'top_cwes_by_threshold': {}
        }
    }

def get_complete_vulnerability_info(
    cve_id: str,
    cve_info_path: str,
    cve_refs_path: str,
    output_dir: str = None
) -> Tuple[Dict[str, Any], Optional[str]]:
    """
    Retrieves all available information for a vulnerability.
    
    Args:
        cve_id: The CVE identifier
        cve_info_path: Base path to CVE information files
        cve_refs_path: Base directory for reference content
        output_dir: Optional directory to store similarity data files
        
    Returns:
        Tuple containing:
        - Dictionary with vulnerability information including:
            - cve_id: The CVE identifier
            - description: Basic vulnerability description
            - key_phrases: Extracted key phrases
            - similar_info: Enhanced similarity information including:
                - cwe_distribution: CWE distributions at different thresholds
                - cwe_consensus: Most common CWE
                - similarity_stats: Detailed similarity statistics
            - similarity_summary: Summarized similarity insights
        - Optional reference content string
    """
    try:
        logger.info(f"Gathering complete vulnerability information for {cve_id}")
        
        # Get basic vulnerability information
        description = get_vulnerability_description(cve_id, cve_info_path)
        if not description:
            logger.warning(f"No description found for {cve_id}")
            
        key_phrases = get_vulnerability_key_phrases(cve_id, cve_info_path)
        if not key_phrases:
            logger.warning(f"No key phrases found for {cve_id}")
            
        reference_content = get_vulnerability_reference_content(cve_id, cve_refs_path)
        if not reference_content:
            logger.debug(f"No reference content found for {cve_id}")
        
        # Get enhanced similar CVE information using key phrases
        weakness = key_phrases.get('weakness', '')
        rootcause = key_phrases.get('rootcause', '')
        similar_info = get_similar_cve_info(
            cve_id, 
            output_dir=output_dir,  # Pass output directory for saving
            weakness=weakness, 
            rootcause=rootcause
        )
        
        # Create a summary of similarity insights
        similarity_summary = _create_similarity_summary(similar_info)
        
        # Combine all information
        vulnerability_info = {
            'cve_id': cve_id,
            'description': description,
            'key_phrases': key_phrases,
            'similar_info': similar_info,
            'similarity_summary': similarity_summary
        }
        
        logger.info(f"Successfully gathered complete information for {cve_id}")
        if similarity_summary['consensus_cwe']:
            logger.info(f"Consensus CWE for {cve_id}: {similarity_summary['consensus_cwe']}")
        
        return vulnerability_info, reference_content
        
    except Exception as e:
        logger.error(f"Error getting complete vulnerability info for {cve_id}: {str(e)}")
        return {}, None

def _create_similarity_summary(similar_info: Dict[str, Any]) -> Dict[str, Any]:
    """
    Create a summarized view of the similarity information optimized for LLM consumption.
    
    Args:
        similar_info: The complete similarity information from get_similar_cve_info
        
    Returns:
        Dictionary containing summarized insights including:
        - consensus_cwe: The most common CWE
        - top_cwes: List of top CWEs across all thresholds
        - confidence_levels: Summary of CWEs at different confidence levels
        - total_samples: Total number of similar CVEs analyzed
    """
    if not similar_info or not similar_info.get('cwe_distribution'):
        return {
            'consensus_cwe': '',
            'top_cwes': [],
            'confidence_levels': {},
            'total_samples': 0
        }
    
    try:
        # Get the distribution data
        distribution = similar_info['cwe_distribution']
        stats = similar_info['similarity_stats']
        
        # Calculate total samples across all thresholds
        total_samples = sum(
            stats['total_samples_by_threshold'].values()
        )
        
        # Get thresholds and sort them
        thresholds = sorted([int(t) for t in distribution.keys()], reverse=True)
        
        # Get all CWEs across all thresholds
        all_cwes = {}
        for threshold_str in distribution:
            threshold_data = distribution[threshold_str]
            cwe_counts = threshold_data['cwe_counts']
            for cwe, count in cwe_counts.items():
                if cwe not in all_cwes:
                    all_cwes[cwe] = 0
                all_cwes[cwe] += count
        
        # Get top 3 CWEs
        top_cwes = sorted(
            [(cwe, count) for cwe, count in all_cwes.items()],
            key=lambda x: x[1],
            reverse=True
        )[:3]
        
        # Create confidence level summaries
        # High: 95%+, Medium: 85-94%, Low: <85%
        confidence_levels = {
            'high': [],
            'medium': [],
            'low': []
        }
        
        for threshold in thresholds:
            threshold_str = str(threshold)
            if threshold_str not in distribution:
                continue
                
            threshold_data = distribution[threshold_str]
            cwe_counts = threshold_data['cwe_counts']
            top_cwes_threshold = sorted(
                [(cwe, count) for cwe, count in cwe_counts.items()],
                key=lambda x: x[1],
                reverse=True
            )[:3]
            
            if threshold >= 95:
                confidence_levels['high'].extend([cwe for cwe, _ in top_cwes_threshold])
            elif threshold >= 85:
                confidence_levels['medium'].extend([cwe for cwe, _ in top_cwes_threshold])
            else:
                confidence_levels['low'].extend([cwe for cwe, _ in top_cwes_threshold])
        
        # Remove duplicates while preserving order
        for level in confidence_levels:
            confidence_levels[level] = list(dict.fromkeys(confidence_levels[level]))
        
        return {
            'consensus_cwe': similar_info['cwe_consensus'],
            'top_cwes': top_cwes,
            'confidence_levels': confidence_levels,
            'total_samples': total_samples
        }
        
    except Exception as e:
        logger.error(f"Error creating similarity summary: {str(e)}")
        return {
            'consensus_cwe': '',
            'top_cwes': [],
            'confidence_levels': {},
            'total_samples': 0
        }
